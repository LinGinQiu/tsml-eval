import os
from abc import abstractmethod
from datetime import datetime

import torch
import torch.nn as nn

from TimesNet.data_provider.uea import load_experiment_data
from TimesNet.models import (
    MICN,
    Autoformer,
    Crossformer,
    DLinear,
    ETSformer,
    FEDformer,
    FiLM,
    FreTS,
    Informer,
    Koopa,
    LightTS,
    MambaSimple,
    MultiPatchFormer,
    Nonstationary_Transformer,
    PatchTST,
    PAttn,
    Pyraformer,
    Reformer,
    SCINet,
    SegRNN,
    TemporalFusionTransformer,
    TiDE,
    TimeMixer,
    TimesNet,
    TimeXer,
    Transformer,
    TSMixer,
    WPMixer,
    iTransformer,
)
from TimesNet.utils.experiments import check_existing_results, stratified_resample_data


class Exp_Basic:
    def __init__(self, args):
        self.args = args
        self.model_dict = {
            "TimesNet": TimesNet,
            "Autoformer": Autoformer,
            "Transformer": Transformer,
            "Nonstationary_Transformer": Nonstationary_Transformer,
            "DLinear": DLinear,
            "FEDformer": FEDformer,
            "Informer": Informer,
            "LightTS": LightTS,
            "Reformer": Reformer,
            "ETSformer": ETSformer,
            "PatchTST": PatchTST,
            "Pyraformer": Pyraformer,
            "MICN": MICN,
            "Crossformer": Crossformer,
            "FiLM": FiLM,
            "iTransformer": iTransformer,
            "Koopa": Koopa,
            "TiDE": TiDE,
            "FreTS": FreTS,
            "MambaSimple": MambaSimple,
            "TimeMixer": TimeMixer,
            "TSMixer": TSMixer,
            "SegRNN": SegRNN,
            "TemporalFusionTransformer": TemporalFusionTransformer,
            "SCINet": SCINet,
            "PAttn": PAttn,
            "TimeXer": TimeXer,
            "WPMixer": WPMixer,
            "MultiPatchFormer": MultiPatchFormer,
        }
        if args.model == "Mamba":
            print("Please make sure you have successfully installed mamba_ssm")
            from TimesNet.models import Mamba

            self.model_dict["Mamba"] = Mamba

        self.first_comment = None
        self.args.num_class = None
        self.time_fit = None
        self.device = self._acquire_device()
        self.data_zip = self._prepare_experiment()
        self.model = self._build_model()

    def _acquire_device(self):
        if (
            self.args.use_gpu
            and self.args.gpu_type == "cuda"
            and torch.cuda.is_available()
        ):
            if self.args.use_multi_gpu and torch.cuda.device_count() > 1:
                print(f"Using {torch.cuda.device_count()} GPUs")
                device = torch.device("cuda")
            else:
                os.environ["CUDA_VISIBLE_DEVICES"] = str(self.args.gpu)
                device = torch.device(f"cuda:0")
                print(f"Use single GPU: cuda:{self.args.gpu}")
        elif self.args.use_gpu and self.args.gpu_type == "cuda":
            print("⚠️ Warning: GPU requested but CUDA not available. Using CPU instead.")
            device = torch.device("cpu")
        elif self.args.use_gpu and self.args.gpu_type == "mps":
            device = torch.device("mps")
            print("Use GPU: mps")
        else:
            device = torch.device("cpu")
            print("Use CPU")
        return device

    def _prepare_experiment(self):
        build_test_file, build_train_file = check_existing_results(
            self.args.results_path,
            self.args.classifier_name,
            self.args.dataset,
            self.args.resample_id,
            self.args.overwrite,
            True,
            self.args.build_train_file,
        )
        if not build_test_file and not build_train_file:
            print("All files exist and not overwriting, skipping.")
            exit(0)

        X_train, y_train, X_test, y_test, resample = load_experiment_data(
            self.args.problem_path,
            self.args.dataset,
            self.args.resample_id,
            self.args.predefined_resample,
        )
        if resample:
            X_train, y_train, X_test, y_test = stratified_resample_data(
                X_train, y_train, X_test, y_test, random_state=self.args.resample_id
            )
        import numpy as np
        from sklearn import preprocessing

        le = preprocessing.LabelEncoder()
        y_train = le.fit_transform(y_train)
        y_test = le.transform(y_test)

        encoder_dict = {label: i for i, label in enumerate(le.classes_)}
        n_classes = len(np.unique(y_train))
        self.args.num_class = n_classes
        self.classes_ = np.unique(y_train)
        self.first_comment = (
            "Generated by run_classification_experiment on "
            f"{datetime.now().strftime('%m/%d/%Y, %H:%M:%S')}. "
            f"Encoder dictionary: {str(encoder_dict)}"
        )
        if self.args.data_transform_name:
            print(
                f"before data transformation, data distribution:{np.unique(y_train, return_counts=True)}"
            )
            from tsml_eval.experiments._get_data_transform import (
                get_data_transform_by_name,
            )

            data_transforms = get_data_transform_by_name(
                self.args.data_transform_name,
                dataset_name=self.args.dataset,
                random_state=self.args.resample_id,
            )
            if not isinstance(data_transforms, list):
                data_transforms = [data_transforms]
            for transform in data_transforms:
                transform_results = transform.fit_transform(X_train, y_train)
                if isinstance(transform_results, tuple) and len(transform_results) == 2:
                    # If the transformer returns a tuple of length 2, assume it is (X, y)
                    X_train, y_train = transform_results
                else:
                    X_train = transform_results

                if not self.args.transform_train_only:
                    transform_results = transform.transform(X_test, y_test)
                    if (
                        isinstance(transform_results, tuple)
                        and len(transform_results) == 2
                    ):
                        X_test, y_test = transform_results
                    else:
                        X_test = transform_results
            print(
                f"after data transformation, data distribution:{np.unique(y_train, return_counts=True)}"
            )

        return {"train": (X_train, y_train), "test": (X_test, y_test)}

    def _build_model(self):
        model = (
            self.model_dict[self.args.model].Model(self.args).float().to(self.device)
        )
        if (
            self.args.use_multi_gpu
            and self.args.use_gpu
            and torch.cuda.device_count() > 1
        ):
            print(f"Using {torch.cuda.device_count()} GPUs")
            model = nn.DataParallel(model)
        return model

    def log_vram_usage(self, epoch=None):
        import torch

        if not torch.cuda.is_available():
            return
        tag = f"[Epoch {epoch}]" if epoch is not None else ""
        for i in range(torch.cuda.device_count()):
            print(
                f"{tag} GPU {i} | "
                f"Allocated: {torch.cuda.memory_allocated(i) / 1024 ** 2:.2f} MB | "
                f"Reserved:  {torch.cuda.memory_reserved(i) / 1024 ** 2:.2f} MB | "
                f"Max:       {torch.cuda.max_memory_allocated(i) / 1024 ** 2:.2f} MB"
            )

    @abstractmethod
    def _get_data(self, flag):
        pass

    @abstractmethod
    def vali(self, vali_data, vali_loader, criterion):
        pass

    @abstractmethod
    def train(self, setting):
        pass

    @abstractmethod
    def test(self, setting, test=0):
        pass
